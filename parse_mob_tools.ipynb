{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from  dateutil.parser import parse\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    \"\"\"\n",
    "    Loads a CSV file into a dataframe and drops NaN columns\n",
    "    input: Path to a csv file\n",
    "    output: Dataframe\n",
    "    \"\"\"\n",
    "    # Find the header row\n",
    "    num_rows = find_header_row(file)\n",
    "    df = pd.read_csv(file, skiprows=num_rows)\n",
    "    # Drop columns where all values are NaN\n",
    "    df = df.dropna(axis='columns', how='all')\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_header_row(file):\n",
    "    \"\"\"\n",
    "    Read each line in a CSV file and return a row number for the header\n",
    "    input: Path to a csv file\n",
    "    output: integer (the row number)\n",
    "    \"\"\"\n",
    "    with open(file,'r') as infile:\n",
    "        reader = csv.reader(infile, delimiter=',', quotechar='\"')\n",
    "        row_num = 0\n",
    "        for row in reader:\n",
    "            if (row[0] == 'ID') | (row[0] == 'TR ID#') | (row[0] == 'Legal First Name'):\n",
    "                break\n",
    "            else:\n",
    "                row_num += 1\n",
    "                next\n",
    "    return(row_num)\n",
    "\n",
    "\n",
    "def write_csv(file, df):\n",
    "    \"\"\"\n",
    "    Writes a CSV file to the \"cleaned\" directory\n",
    "    input: a cleaned dataframe (after load_data())\n",
    "    output: csv file\n",
    "    \"\"\"\n",
    "    path_cleaned = 'cleaned/'\n",
    "    os.makedirs(path_cleaned, exist_ok=True)\n",
    "    path_cleaned_file = path_cleaned+file\n",
    "    df.to_csv(path_cleaned_file, index=None)\n",
    "    \n",
    "    \n",
    "def parse_op_name(filename):\n",
    "    \"\"\"\n",
    "    Parses an operation name from a mobtool's file name\n",
    "    \"\"\"\n",
    "    filename_parts = re.split(', | - ', filename)\n",
    "    for part in filename_parts:\n",
    "        part = part.upper()\n",
    "        # Strip superfluous text, punctuation, and characters\n",
    "        if \"op\".upper() in part:\n",
    "            op_name = part.replace(\"PERSONNEL PLANNING TOOL\", \"\").replace(\"MOBILIZATION TOOL\",\"\")\n",
    "            op_name = op_name.replace(\"_\", \"\").replace(\"'\",\"\")\n",
    "            if \"operation\".upper() not in op_name:\n",
    "                op_name= op_name.replace(\"op\".upper(), \"Operation\".upper())\n",
    "    return op_name.strip()\n",
    "\n",
    "\n",
    "def standardize_dates(df):\n",
    "    mapper={}\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            dt = parse(str(col))\n",
    "            new_date = dt.strftime('%Y-%m-%d')\n",
    "            mapper[col] = new_date \n",
    "        except:\n",
    "            next\n",
    "    df.rename(mapper, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_start_end_dates(series):\n",
    "    \"\"\"\n",
    "    Returns dates a volunteer first and last deployed. Also returns total days deployed.\n",
    "    This does not take into account that volunteers can deploy multiple times on an op and \n",
    "    does not count travel days.\n",
    "    \n",
    "    input: a Pandas series (dataframe row) \n",
    "    output: tuple, first date, last date of deployment, and total days deployed\n",
    "    \n",
    "    This requires the dates to be standardized and numercial\n",
    "    \"\"\"\n",
    "    df = series.to_frame().transpose()\n",
    "    \n",
    "    dropcols=[]\n",
    "    for col in df.columns:\n",
    "        try: \n",
    "            int(col[0])        \n",
    "        except:\n",
    "            dropcols.append(col)\n",
    "    df.drop(columns=dropcols, inplace=True)\n",
    "    df.dropna(axis=1, inplace=True)\n",
    "    \n",
    "    dates=[]\n",
    "    for col in df.columns:\n",
    "        dt = parse(str(col))\n",
    "        dates.append(dt.strftime('%Y-%m-%d'))\n",
    "    if len(dates) > 0:\n",
    "        start = min(dates)\n",
    "        end = max(dates)\n",
    "        total_days_deployed = len(df.columns)\n",
    "        return start, end, total_days_deployed\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "    \n",
    "def standarize_phone_number(number):\n",
    "    number = str(number)\n",
    "    if number == 'nan':\n",
    "        return None\n",
    "    \n",
    "    # 123.456.7890\n",
    "    elif len(number.split('.')) == 3:\n",
    "        return number\n",
    "    \n",
    "    # 123.4567890\n",
    "    elif len(number.split('.')) == 2:\n",
    "        new_number = number.replace('.','')\n",
    "        new_number = '.'.join([new_number[:3], new_number[3:6], new_number[-4:]])\n",
    "        return new_number\n",
    "    \n",
    "    # 123-456-7890\n",
    "    elif len(number.split('-')) == 3:\n",
    "        new_number = number.replace(\"-\", \".\")\n",
    "        return new_number\n",
    "    \n",
    "    # 1234567890\n",
    "    elif len(number) == 10:\n",
    "        new_number = '.'.join([number[:3], number[3:6], number[-4:]])\n",
    "        return new_number\n",
    "    \n",
    "    # (123)4567890\n",
    "    elif len(number.split(\")\")) == 2:\n",
    "        new_number = number.replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\")\n",
    "        new_number = '.'.join([new_number[:3], new_number[3:6], new_number[-4:]])\n",
    "        return new_number\n",
    "    \n",
    "    # Return whatever it came in as\n",
    "    else:\n",
    "        return number\n",
    "\n",
    "    \n",
    "def merge_dataframes(dfs):\n",
    "    # Concat all dataframes\n",
    "    final_df = pd.concat(dfs, axis=0, join=\"outer\", sort=True)\n",
    "    \n",
    "    # Merge 'First name' and 'Legal First Name' columns\n",
    "    final_df['First Name'] = final_df['First Name'].where(final_df['Legal First Name'].isnull(), final_df['Legal First Name'])\n",
    "    final_df['Position'] = final_df['Position'].where(final_df['Skill / Position (One Word)'].isnull(), final_df['Skill / Position (One Word)'])\n",
    "\n",
    "    final_columns = [\n",
    "        'TR ID#', 'OP_NAME', 'START_DATE', 'END_DATE', 'TOTAL_DAYS',\n",
    "        'TOTAL_HOURS', 'IMPACT_DOLLARS', 'First Name', 'Last Name',\n",
    "        'Email', 'PHONE_NUMBER', 'Position']\n",
    "    final_df = final_df[final_columns]\n",
    "    \n",
    "    # Drop rows where these columns are all Null values \n",
    "    # This cleans up GSheets that have tons of extra empty rows\n",
    "    drop_columns = ['TR ID#','First Name', 'Last Name', 'Email', \n",
    "        'PHONE_NUMBER', 'Position']\n",
    "    \n",
    "    final_df.dropna(subset=drop_columns, how='all', inplace=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPERATION SKIPPING CHRISTMAS\n",
      "OPERATION CRAZY TRAIN\n",
      "OPERATION COAL MINERS DAUGHTER\n",
      "OPERATION DOUBLE TROUBLE\n",
      "OPERATION OLD PUT\n",
      "OPERATION TWISTED TRUNK\n",
      "OPERATION HUCKLEBERRY HUSTLE\n",
      "OPERATION PALMETTO PUNCH\n",
      "OPERATION RIGHT STUFF\n",
      "OPERATION BARBED WIRE\n",
      "OPERATION OLD ANCHOR\n",
      "OPERATION BIG DIG\n",
      "OPERATION BREDO RISING\n",
      "OPERATION SLEEPING BEAR\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def main(input_dir):\n",
    "    if \"/\" not in input_dir:\n",
    "        input_dir = input_dir + \"/\"\n",
    "    input_files = [f.strip(\"input/\") for f in glob.glob(input_dir+'/*.csv')]\n",
    "    \n",
    "    dfs=[]\n",
    "    for file in input_files:\n",
    "        # Load and clean\n",
    "        df = load_data(input_dir+file)\n",
    "           \n",
    "        # Parse Op name and add to the dataframe\n",
    "        op_name = parse_op_name(file)\n",
    "        df['OP_NAME'] = op_name\n",
    "        print(op_name)\n",
    "        \n",
    "        # Standardize the format of all the dates\n",
    "        df = standardize_dates(df)\n",
    "\n",
    "        # Get the dates\n",
    "        for row in range(len(df)):\n",
    "            series = df.iloc[row]\n",
    "            start, end, total_days_deployed = get_start_end_dates(series)\n",
    "            df.at[row,'START_DATE'] = str(start)\n",
    "            df.at[row,'END_DATE'] = str(end)\n",
    "            df.at[row,'TOTAL_DAYS'] = total_days_deployed\n",
    "            \n",
    "        # Total hours based on standard 10 hour day\n",
    "        df['TOTAL_HOURS'] = df['TOTAL_DAYS'] * 10 # Standarad 10 hour day\n",
    "        \n",
    "        # Total Impact dollars\n",
    "        df['IMPACT_DOLLARS'] = df['TOTAL_HOURS'] * 28.15\n",
    "        \n",
    "        # Standardize phone numbers\n",
    "        if 'Phone #' in df.columns:\n",
    "            df['PHONE_NUMBER'] = df['Phone #'].apply(standarize_phone_number)\n",
    "        if 'Contact Number (ex:143.143.1234)' in df.columns:\n",
    "            df['PHONE_NUMBER'] = df['Contact Number (ex:143.143.1234)'].apply(standarize_phone_number)\n",
    "        \n",
    "        # Write to file\n",
    "        write_csv(file, df)\n",
    "        \n",
    "        # Append to dataframes list\n",
    "        dfs.append(df)        \n",
    "    \n",
    "    # Concat all dataframes\n",
    "    final_df = merge_dataframes(dfs)\n",
    "    \n",
    "    # Write full dataset to file\n",
    "    write_csv('raw_deployer_dataset.csv', final_df)\n",
    "        \n",
    "    print(\"Done.\")\n",
    "    return dfs, final_df\n",
    "\n",
    "dfs, final_df = main('input/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
